{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['article_id', 'source_id', 'source_name', 'author', 'title',\n",
      "       'description', 'url', 'url_to_image', 'published_at', 'content',\n",
      "       'category', 'full_content'],\n",
      "      dtype='object')\n",
      "First few rows of DataFrame:\n",
      "   article_id source_id                   source_name  \\\n",
      "0       89541       NaN  International Business Times   \n",
      "1       89542       NaN                    Prtimes.jp   \n",
      "2       89543       NaN                      VOA News   \n",
      "3       89545       NaN            The Indian Express   \n",
      "4       89547       NaN           The Times of Israel   \n",
      "\n",
      "                                       author  \\\n",
      "0                              Paavan MATHEMA   \n",
      "1                                         NaN   \n",
      "2  webdesk@voanews.com (Agence France-Presse)   \n",
      "3                                   Editorial   \n",
      "4                                 Jacob Magid   \n",
      "\n",
      "                                               title  \\\n",
      "0  UN Chief Urges World To 'Stop The Madness' Of ...   \n",
      "1              RANDEBOOよりワンランク上の大人っぽさが漂うニットとベストが新登場。   \n",
      "2  UN Chief Urges World to 'Stop the Madness' of ...   \n",
      "3  Sikkim warning: Hydroelectricity push must be ...   \n",
      "4  200 foreigners, dual nationals cut down in Ham...   \n",
      "\n",
      "                                         description  \\\n",
      "0  UN Secretary-General Antonio Guterres urged th...   \n",
      "1  [株式会社Ainer]\\nRANDEBOO（ランデブー）では2023年7月18日(火)より公...   \n",
      "2  UN Secretary-General Antonio Guterres urged th...   \n",
      "3  Ecologists caution against the adverse effects...   \n",
      "4  France lost 35 citizens, Thailand 33, US 31, U...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.ibtimes.com/un-chief-urges-world-s...   \n",
      "1  https://prtimes.jp/main/html/rd/p/000000147.00...   \n",
      "2  https://www.voanews.com/a/un-chief-urges-world...   \n",
      "3  https://indianexpress.com/article/opinion/edit...   \n",
      "4  https://www.timesofisrael.com/200-foreigners-d...   \n",
      "\n",
      "                                        url_to_image  \\\n",
      "0  https://d.ibtimes.com/en/full/4496078/nepals-g...   \n",
      "1  https://prtimes.jp/i/32220/147/ogp/d32220-147-...   \n",
      "2  https://gdb.voanews.com/01000000-0a00-0242-60f...   \n",
      "3  https://images.indianexpress.com/2023/10/edit-...   \n",
      "4  https://static.timesofisrael.com/www/uploads/2...   \n",
      "\n",
      "                 published_at  \\\n",
      "0  2023-10-30 10:12:35.000000   \n",
      "1  2023-10-06 04:40:02.000000   \n",
      "2  2023-10-30 10:53:30.000000   \n",
      "3  2023-10-06 01:20:24.000000   \n",
      "4  2023-10-27 01:08:34.000000   \n",
      "\n",
      "                                             content category  \\\n",
      "0  UN Secretary-General Antonio Guterres urged th...    Nepal   \n",
      "1  RANDEBOO2023718()WEB2023 Autumn Winter \\n\"Nepa...    Nepal   \n",
      "2  Kathmandu, Nepal  UN Secretary-General Antonio...    Nepal   \n",
      "3  At least 14 persons lost their lives and more ...    Nepal   \n",
      "4  Scores of foreign citizens were killed, taken ...    Nepal   \n",
      "\n",
      "                                        full_content  \n",
      "0  UN Secretary-General Antonio Guterres urged th...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3  At least 14 persons lost their lives and more ...  \n",
      "4                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the connection string\n",
    "DATABASE_TYPE = 'postgresql'\n",
    "DBAPI = 'psycopg2'\n",
    "ENDPOINT = 'localhost'\n",
    "USER = 'postgres'\n",
    "PASSWORD = '123456'\n",
    "PORT = 5432\n",
    "DATABASE = 'modeldb'\n",
    "\n",
    "# Create an engine and connect to the PostgreSQL database\n",
    "engine = create_engine(f\"{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{ENDPOINT}:{PORT}/{DATABASE}\")\n",
    "\n",
    "# Load CSV data into a DataFrame\n",
    "news_df = pd.read_csv(r'D:\\projects\\10ac_week0\\data\\data.csv')\n",
    "\n",
    "# Print the column names and the first few rows of the DataFrame\n",
    "print(\"Columns in DataFrame:\", news_df.columns)\n",
    "print(\"First few rows of DataFrame:\")\n",
    "print(news_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles table dropped successfully.\n",
      "Sources table dropped successfully.\n",
      "Sources table created successfully.\n",
      "Articles table created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove rows where 'source_id' is NaN\n",
    "news_df = news_df.dropna(subset=['source_id'])\n",
    "\n",
    "# Connect to the 'modeldb' database using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"modeldb\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123456\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# SQL command to drop the 'articles' table if it exists\n",
    "drop_articles_table = \"DROP TABLE IF EXISTS articles CASCADE;\"\n",
    "cursor.execute(drop_articles_table)\n",
    "conn.commit()\n",
    "print(\"Articles table dropped successfully.\")\n",
    "\n",
    "# SQL command to drop the 'sources' table if it exists\n",
    "drop_sources_table = \"DROP TABLE IF EXISTS sources;\"\n",
    "cursor.execute(drop_sources_table)\n",
    "conn.commit()\n",
    "print(\"Sources table dropped successfully.\")\n",
    "\n",
    "# SQL command to create the 'sources' table with a primary key\n",
    "create_sources_table = \"\"\"\n",
    "CREATE TABLE sources (\n",
    "    source_id SERIAL PRIMARY KEY,\n",
    "    source_name VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL command\n",
    "cursor.execute(create_sources_table)\n",
    "conn.commit()\n",
    "print(\"Sources table created successfully.\")\n",
    "\n",
    "# SQL command to create the 'articles' table\n",
    "create_articles_table = \"\"\"\n",
    "CREATE TABLE articles (\n",
    "    article_id SERIAL PRIMARY KEY,\n",
    "    source_id INTEGER REFERENCES sources(source_id) ON DELETE CASCADE,\n",
    "    title TEXT,\n",
    "    description TEXT,\n",
    "    url TEXT,\n",
    "    published_at TIMESTAMP,\n",
    "    content TEXT,\n",
    "    category VARCHAR(255),\n",
    "    full_content TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL command\n",
    "cursor.execute(create_articles_table)\n",
    "conn.commit()\n",
    "print(\"Articles table created successfully.\")\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sources data inserted successfully.\n",
      "Warning: Some required columns for 'articles' are missing. Existing columns: Index(['article_id', 'source_id_x', 'source_name', 'author', 'title',\n",
      "       'description', 'url', 'url_to_image', 'published_at', 'content',\n",
      "       'category', 'full_content', 'source_id_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Prepare the 'sources' DataFrame, excluding 'source_id'\n",
    "if 'source_name' in news_df.columns:\n",
    "    sources_df = news_df[['source_name']].drop_duplicates()\n",
    "else:\n",
    "    print(f\"Warning: 'source_name' column is missing from the DataFrame. Existing columns: {news_df.columns}\")\n",
    "\n",
    "# Insert data into the 'sources' table without the 'source_id' column\n",
    "if 'source_name' in news_df.columns:\n",
    "    sources_df.to_sql('sources', con=engine, if_exists='append', index=False)\n",
    "    print(\"Sources data inserted successfully.\")\n",
    "else:\n",
    "    print(\"Skipping 'sources' table insertion due to missing columns.\")\n",
    "\n",
    "# Now fetch the auto-generated source_ids from the database and merge them back into the DataFrame\n",
    "query = \"SELECT source_id, source_name FROM sources;\"\n",
    "source_ids_df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Merge the auto-generated source_ids back with the original DataFrame\n",
    "news_df = pd.merge(news_df, source_ids_df, on='source_name', how='left')\n",
    "\n",
    "# Prepare the 'articles' DataFrame, now including the correct source_id\n",
    "article_columns = ['source_id', 'title', 'description', 'url', 'published_at', 'content', 'category', 'full_content']\n",
    "if all(col in news_df.columns for col in article_columns):\n",
    "    articles_df = news_df[article_columns]\n",
    "    # Insert data into the 'articles' table\n",
    "    articles_df.to_sql('articles', con=engine, if_exists='replace', index=False)\n",
    "    print(\"Articles data inserted successfully.\")\n",
    "else:\n",
    "    print(f\"Warning: Some required columns for 'articles' are missing. Existing columns: {news_df.columns}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
